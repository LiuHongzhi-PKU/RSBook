{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:25:33.832980Z",
     "start_time": "2020-06-27T04:25:32.819575Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "from utils import Interactions\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 设置是否使用隐式反馈\n",
    "IMPLICT=True\n",
    "# 设置是否使用超小数据集测试\n",
    "SMALL=False\n",
    "\n",
    "# for reproducibility\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "\n",
    "# To compute probalities\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def getDataLoader(data_path, batch_size=2048):\n",
    "    # load train data\n",
    "    data_fields = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    # all data file\n",
    "    data_df = pd.read_table(data_path, names=data_fields)\n",
    "    if SMALL:\n",
    "        data_df = data_df.sample(n=int(len(data_df) * 0.1), replace=False)\n",
    "    if IMPLICT:\n",
    "        data_df.rating = (data_df.rating >= 5).astype(np.float32)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(data_df['user_id'])\n",
    "    data_df['user_id']=le.transform(data_df['user_id'])\n",
    "    le.fit(data_df['item_id'])\n",
    "    data_df['item_id']=le.transform(data_df['item_id'])\n",
    "\n",
    "    df_train = data_df.sample(n=int(len(data_df) * 0.8), replace=False)\n",
    "    df_test = data_df.drop(df_train.index, axis=0)\n",
    "\n",
    "    # get user number\n",
    "    n_users = max(data_df['user_id'].values)+1\n",
    "    # get item number\n",
    "    n_items = max(data_df['item_id'].values)+1\n",
    "\n",
    "    print(\"Initialize end.The user number is:%d,item number is:%d\" % (n_users, n_items))\n",
    "    train_loader = data.DataLoader(\n",
    "        Interactions(df_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_loader = data.DataLoader(\n",
    "        Interactions(df_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loaders = {'train': train_loader,\n",
    "               'valid': test_loader}\n",
    "\n",
    "    return (n_users,n_items ), loaders\n",
    "\n",
    "#\n",
    "class LFM(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=10, lr=0.01, weight_decay=0.01, sparse=False,topn=10, device=torch.device(\"cpu\")):\n",
    "        super(LFM, self).__init__()\n",
    "\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.device = device\n",
    "        self.topn=topn\n",
    "\n",
    "        # get factor number\n",
    "        self.n_factors = n_factors\n",
    "        self.user_biases = nn.Embedding(self.n_users, 1, sparse=sparse)\n",
    "        self.item_biases = nn.Embedding(self.n_items, 1, sparse=sparse)\n",
    "        self.user_embeddings = nn.Embedding(self.n_users, self.n_factors, sparse=sparse)\n",
    "        self.item_embeddings = nn.Embedding(self.n_items, self.n_factors, sparse=sparse)\n",
    "\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(),\n",
    "                                   lr=lr, weight_decay=weight_decay)\n",
    "        self=self.to(self.device)\n",
    "\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        users=users.to(self.device)\n",
    "        items = items.to(self.device)\n",
    "        ues = self.user_embeddings(users)\n",
    "        uis = self.item_embeddings(items)\n",
    "\n",
    "        preds = self.user_biases(users) # b 1\n",
    "        preds += self.item_biases(items)# b 1\n",
    "        preds += ((ues) * (uis)).sum(dim=1,keepdim=True)\n",
    "        # preds=torch.sigmoid(preds)\n",
    "\n",
    "        return preds.squeeze(1)\n",
    "\n",
    "    def fit(self, loaders, epochs=5):\n",
    "        # training cycle\n",
    "        for epoch in range(epochs):\n",
    "            losses = {'train': 0., 'valid': 0}\n",
    "\n",
    "            for phase in ['train', 'valid']:\n",
    "\n",
    "                if phase == 'train':\n",
    "                    self.train()\n",
    "                else:\n",
    "                    self.eval()\n",
    "                pbar = tqdm(enumerate(loaders[phase]),\n",
    "                            total=len(loaders[phase]),\n",
    "                            desc='({0}:{1:^3})'.format(phase, epoch+1))\n",
    "                for batch_idx, ((row, col), val) in pbar:\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    row = row.long()\n",
    "                    col = col.long()\n",
    "                    val = val.float().to(self.device)\n",
    "                    preds = self.forward(row, col)\n",
    "                    loss = nn.MSELoss(reduction='sum')(preds, val)\n",
    "\n",
    "                    losses[phase] += loss.item()\n",
    "                    batch_loss = loss.item() / row.size()[0]\n",
    "                    pbar.set_postfix(train_loss=batch_loss)\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "\n",
    "                losses[phase] /= len(loaders[phase].dataset)\n",
    "\n",
    "            # after each epoch check if we improved roc auc and if yes - save model\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                y_pred,y_true = [],[]\n",
    "\n",
    "                for ((row, col), val) in loaders['valid']:\n",
    "                    row = row.long()\n",
    "                    col = col.long()\n",
    "                    val = val.float()\n",
    "                    preds = self.forward(row, col)\n",
    "                    if IMPLICT:\n",
    "                        preds = sigmoid(preds.cpu().numpy())\n",
    "                    y_pred += preds.tolist()\n",
    "                    y_true += val.tolist()\n",
    "                y_true,y_pred=np.array(y_true), np.array(y_pred)\n",
    "                if IMPLICT:\n",
    "                    epoch_score = roc_auc_score(y_true,y_pred)\n",
    "                    score='auc'\n",
    "                else:\n",
    "                    epoch_score=sum([(y - x) ** 2 for x, y in zip(y_true, y_pred)]) / len(y_pred)\n",
    "                    score='mse'\n",
    "\n",
    "\n",
    "                user_item=loaders['valid'].dataset.user_item\n",
    "                items = torch.arange(self.n_items).long()\n",
    "                hit, rec_count, test_count,all_rec_items = 0,0,0,set()\n",
    "                train_ui=loaders['train'].dataset.user_item\n",
    "                for u in user_item:\n",
    "                    target_items=user_item[u]\n",
    "                    if u not in train_ui:continue\n",
    "                    seen_items = np.array(list(train_ui[u].keys()))\n",
    "\n",
    "                    users=[int(u)]*self.n_items\n",
    "                    users = torch.Tensor(users).long()\n",
    "                    scores=self.forward(users,items)\n",
    "                    scores[seen_items]=-1e9\n",
    "                    recs=np.argsort(scores)[-self.topn:].tolist()\n",
    "\n",
    "                    for item in recs:  # 遍历给user推荐的物品\n",
    "                        if item in target_items:  # 测试集中有该物品\n",
    "                            hit += 1  # 推荐命中+1\n",
    "                        all_rec_items.add(item)\n",
    "                    rec_count += self.topn\n",
    "                    test_count += len(target_items)\n",
    "                    precision = hit / (1.0 * rec_count)\n",
    "                    recall = hit / (1.0 * test_count)\n",
    "                    coverage = len(all_rec_items) / (1.0 * self.n_items)\n",
    "\n",
    "                # # 计算top10的recall、precision、推荐物品覆盖率\n",
    "                # user_item=loaders['valid'].dataset.user_item\n",
    "                # items = torch.arange(self.n_items).long().to(self.device)\n",
    "                # hit, rec_count, test_count,all_rec_items = 0,0,0,set()\n",
    "                # train_ui=loaders['train'].dataset.user_item\n",
    "                # for u in user_item:\n",
    "                #     target_items=user_item[u]\n",
    "                #\n",
    "                #     users=[int(u)]*self.n_items\n",
    "                #     users = torch.Tensor(users).long().to(self.device)\n",
    "                #     scores=self.forward(users,items)\n",
    "                #     if u in train_ui:\n",
    "                #         seen_items = np.array(list(train_ui[u].keys()))\n",
    "                #\n",
    "                #         scores[seen_items]=-1e9\n",
    "                #     else:continue\n",
    "                #     # print('s',len(seen_items))\n",
    "                #     # seen_items = np.array(list(train_ui[u].keys()))\n",
    "                #     # scores[seen_items] = -1e9\n",
    "                #     # print('t',len(seen_items))\n",
    "                #     recs=np.argsort(scores)[-self.topn:].tolist()\n",
    "                #     print('------------')\n",
    "                #     print(seen_items)\n",
    "                #     print(recs)\n",
    "                #     print(scores[recs])\n",
    "                #\n",
    "                #     for item in recs:  # 遍历给user推荐的物品\n",
    "                #         if item in target_items:  # 测试集中有该物品\n",
    "                #             hit += 1  # 推荐命中+1\n",
    "                #         all_rec_items.add(item)\n",
    "                #     rec_count += self.topn\n",
    "                #     test_count += len(target_items)\n",
    "                # precision = hit / (1.0 * rec_count)\n",
    "                # recall = hit / (1.0 * test_count)\n",
    "                # coverage = len(all_rec_items) / (1.0 * self.n_items)\n",
    "\n",
    "            if ((epoch + 1) % 1) == 0:\n",
    "                print(\n",
    "                    f'epoch {epoch + 1} train loss: {losses[\"train\"]:.3f} valid loss {losses[\"valid\"]:.3f} {score} {epoch_score:.3f}')\n",
    "                print('precisioin=%.4f\\trecall=%.4f\\tcoverage=%.4f' % (precision, recall, coverage))\n",
    "                print(hit, len(all_rec_items), len(user_item))\n",
    "\n",
    "        return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:27:22.545135Z",
     "start_time": "2020-06-27T04:25:34.719823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "(train: 1 ):   0%|                                                                              | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize end.The user number is:943,item number is:1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train: 1 ): 100%|███████████████████████████████████████████████████| 40/40 [00:36<00:00,  1.11it/s, train_loss=0.724]\n",
      "(valid: 1 ): 100%|███████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.14it/s, train_loss=0.821]\n",
      "(train: 2 ):   0%|                                                                              | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train loss: 2.697 valid loss 0.770 auc 0.593\n",
      "precisioin=0.0016\trecall=0.0008\tcoverage=0.3216\n",
      "15 541 941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train: 2 ): 100%|███████████████████████████████████████████████████| 40/40 [00:36<00:00,  1.10it/s, train_loss=0.433]\n",
      "(valid: 2 ): 100%|███████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.16it/s, train_loss=0.518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train loss: 0.397 valid loss 0.487 auc 0.641\n",
      "precisioin=0.0013\trecall=0.0006\tcoverage=0.3115\n",
      "12 524 941\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_size, loader=getDataLoader(\"../data/ml-100k/u.data\")\n",
    "    model = LFM(input_size[0],input_size[1])\n",
    "    model.fit(loader,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T06:12:02.729806Z",
     "start_time": "2020-06-27T06:12:02.687918Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data_path=\"../data/ml-100k/u.data\"\n",
    "data_fields = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data_df = pd.read_table(data_path, names=data_fields)\n",
    "data_df.rating = (data_df.rating >= 5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T06:12:13.271818Z",
     "start_time": "2020-06-27T06:12:13.013241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>462.48475</td>\n",
       "      <td>425.530130</td>\n",
       "      <td>0.212010</td>\n",
       "      <td>8.835289e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>266.61442</td>\n",
       "      <td>330.798356</td>\n",
       "      <td>0.408734</td>\n",
       "      <td>5.343856e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.747247e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>254.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.794487e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>447.00000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.828269e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>682.00000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.882600e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>943.00000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.932866e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id        item_id         rating     timestamp\n",
       "count  100000.00000  100000.000000  100000.000000  1.000000e+05\n",
       "mean      462.48475     425.530130       0.212010  8.835289e+08\n",
       "std       266.61442     330.798356       0.408734  5.343856e+06\n",
       "min         1.00000       1.000000       0.000000  8.747247e+08\n",
       "25%       254.00000     175.000000       0.000000  8.794487e+08\n",
       "50%       447.00000     322.000000       0.000000  8.828269e+08\n",
       "75%       682.00000     631.000000       0.000000  8.882600e+08\n",
       "max       943.00000    1682.000000       1.000000  8.932866e+08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:29:05.850450Z",
     "start_time": "2020-06-27T04:29:05.846460Z"
    }
   },
   "outputs": [],
   "source": [
    "loaders=loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:29:37.946834Z",
     "start_time": "2020-06-27T04:29:37.940850Z"
    }
   },
   "outputs": [],
   "source": [
    "user_item=loaders['valid'].dataset.user_item\n",
    "items = torch.arange(model.n_items).long()\n",
    "hit, rec_count, test_count,all_rec_items = 0,0,0,set()\n",
    "train_ui=loaders['train'].dataset.user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:32:42.650976Z",
     "start_time": "2020-06-27T04:32:42.645966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 943)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_item),len(train_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:33:27.554564Z",
     "start_time": "2020-06-27T04:33:27.549577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=list(user_item.keys())[0]\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:33:52.475026Z",
     "start_time": "2020-06-27T04:33:52.471002Z"
    }
   },
   "outputs": [],
   "source": [
    "target_items=user_item[u]\n",
    "seen_items = np.array(list(train_ui[u].keys()))\n",
    "\n",
    "users=[int(u)]*model.n_items\n",
    "users = torch.Tensor(users).long()\n",
    "scores=model.forward(users,items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:33:59.398657Z",
     "start_time": "2020-06-27T04:33:59.393671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 207,  216,  240,  549,  143,  356, 1108,  104,   41,  379,   21,\n",
       "        117,  630,   65,  865,   88,  746,    6,  761,    0,  948,  382,\n",
       "        178,  116,   91,  213,  167,  166,   67,  293,   27, 1224, 1131,\n",
       "        467,  832,  745,   69,  368,  317, 1078,  275,  454,  753,  400,\n",
       "        196, 1044,  171,  180,  179,   87,   79,  267,  722,  185,  885,\n",
       "        684, 1053,  163, 1073,  923,  182,  520,  672,  762, 1118,   70,\n",
       "        558,  245,  527,  234,  264,   57,  366,   52,  723,  231,  507,\n",
       "        108,  650, 1135,  455,  583,  280,  450,  134, 1208,  580,  172,\n",
       "        120,   68,  409,  763, 1117,  536,  661,  508,  457,  290,  952,\n",
       "         94,  161,  155,  233,  364,   31,   89,  187,   51,   61,  595,\n",
       "        432,  940,  199,  215,   30,  711,  157,   19,  208,    8, 1052,\n",
       "        277,   55,   96,  170,   66,  817,   53,  738, 1097, 1106,  221,\n",
       "       1187,  192,   71,  734,  286, 1466,  742,  203,  316, 1167,  954,\n",
       "       1177,  113,   12,  392,    2,  474,   49,  553,  195,  706,   76,\n",
       "        160,   25, 1016,  427,  380,  949,  173,  870,  152,  552,  649,\n",
       "        715, 1047,  731,  168, 1094,  121,  153,  743,  309,   85,  844,\n",
       "        323, 1427,  219,  237, 1038,   99,  565,  814,  289,  659,  925,\n",
       "        190])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:36:58.217073Z",
     "start_time": "2020-06-27T04:36:58.213084Z"
    }
   },
   "outputs": [],
   "source": [
    "target_items=list(target_items.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:35:36.363894Z",
     "start_time": "2020-06-27T04:35:36.357882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6737, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[seen_items].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:37:02.904821Z",
     "start_time": "2020-06-27T04:37:02.897809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0770,  0.0970,  0.1671,  0.1751,  0.1343,  0.0993, -0.1862, -0.1635,\n",
       "         0.6713,  0.1268,  0.4818,  0.4556,  0.1706,  0.0555,  0.0205,  0.3254,\n",
       "         0.1514,  0.2253,  0.0911,  0.4168,  0.2744, -0.5052,  0.1759,  0.0712,\n",
       "         0.4073, -0.0306, -0.0708,  0.1237, -0.0089,  0.3230,  0.2754,  0.2973,\n",
       "         0.3637,  0.5082,  0.7002,  0.2129,  0.2120,  0.2499, -0.0483,  0.7151,\n",
       "         0.1539,  0.3075,  0.2028, -0.0739,  0.0500,  0.2368,  0.0418, -0.0630,\n",
       "        -0.2243,  0.2711], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[target_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for u in user_item:\n",
    "    target_items=user_item[u]\n",
    "    if u not in train_ui:continue\n",
    "    seen_items = np.array(list(train_ui[u].keys()))\n",
    "\n",
    "    users=[int(u)]*model.n_items\n",
    "    users = torch.Tensor(users).long()\n",
    "    scores=model.forward(users,items)\n",
    "    scores[seen_items]=-1e9\n",
    "    recs=np.argsort(scores)[-model.topn:].tolist()\n",
    "\n",
    "    for item in recs:  # 遍历给user推荐的物品\n",
    "        if item in target_items:  # 测试集中有该物品\n",
    "            hit += 1  # 推荐命中+1\n",
    "        all_rec_items.add(item)\n",
    "    rec_count += model.topn\n",
    "    test_count += len(target_items)\n",
    "    precision = hit / (1.0 * rec_count)\n",
    "    recall = hit / (1.0 * test_count)\n",
    "    coverage = len(all_rec_items) / (1.0 * model.n_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
